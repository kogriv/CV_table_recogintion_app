{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ArUMp3syvqO",
        "outputId": "8a63a723-d868-4f01-9858-e9bb1747bd1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 4,850 kB of archives.\n",
            "After this operation, 16.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1 [1,598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr amd64 4.1.1-2build2 [262 kB]\n",
            "Fetched 4,850 kB in 0s (12.7 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123105 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2build2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2build2) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2build2) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr-rus\n",
            "0 upgraded, 1 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 1,274 kB of archives.\n",
            "After this operation, 3,877 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-rus all 1:4.00~git30-7274cfa-1 [1,274 kB]\n",
            "Fetched 1,274 kB in 1s (1,485 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-rus.\n",
            "(Reading database ... 123152 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-rus_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-rus (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr-rus (1:4.00~git30-7274cfa-1) ...\n",
            "Collecting timm\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 timm-0.9.2\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "Successfully installed tokenizers-0.13.3 transformers-4.30.2\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (8.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (8.4.0)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!sudo apt-get install tesseract-ocr-rus\n",
        "\n",
        "!pip install timm\n",
        "!pip install transformers\n",
        "!pip install pytesseract\n",
        "!pip install pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yl-P21ry0r5",
        "outputId": "36de9e98-b4cf-4831-e376-697c89947d80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# импорты сторонних библиотек\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import pytesseract\n",
        "import subprocess\n",
        "\n",
        "\n",
        "# импорты модулей текущего проекта\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n",
        "from transformers import (\n",
        "    AutoImageProcessor,\n",
        "    TableTransformerForObjectDetection,\n",
        "    TableTransformerModel,\n",
        "    DetrImageProcessor,\n",
        "    DetrForObjectDetection,\n",
        ")\n",
        "from PIL import Image\n",
        "from tqdm import trange\n",
        "from os import listdir\n",
        "\n",
        "# настройки\n",
        "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
        "ocr_settings = ' - -l rus --oem 3 --psm 7 --dpi 72 -c tessedit_char_whitelist=\"йцукенгшщзхъфывапролджэячсмитьбю/ЙЦУКЕНГШЩЗХЪФЫВАПРОЛДЖЭЯЧСМИТЬБЮ0123456789().calmg* \"'\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "\n",
        "# константы\n",
        "FILE_PATH = r\"/content/drive/MyDrive/213950.jpg\"\n",
        "CSV_PATH = \"/content/drive/MyDrive/213950.csv\"\n",
        "DIRECTORY = \"/content/drive/MyDrive/workshop/\"\n",
        "SLICES_FOLDER = \"/content/drive/MyDrive/ocr_slices/\"\n",
        "PRETRAINED_MODEL = \"TahaDouaji/detr-doc-table-detection\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M35Kvh5xzsO9"
      },
      "source": [
        "# Модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtZTEmF9y2hI"
      },
      "outputs": [],
      "source": [
        "def order_points(pts):\n",
        "    pts = pts.reshape(4, 2)\n",
        "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
        "    s = pts.sum(axis=1)\n",
        "    rect[0] = pts[np.argmin(s)]\n",
        "    rect[2] = pts[np.argmax(s)]\n",
        "    diff = np.diff(pts, axis=1)\n",
        "    rect[1] = pts[np.argmin(diff)]\n",
        "    rect[3] = pts[np.argmax(diff)]\n",
        "    return rect\n",
        "\n",
        "\n",
        "def calculateDistanceBetween2Points(p1, p2):\n",
        "    dis = ((p2[0] - p1[0]) ** 2 + (p2[1] - p1[1]) ** 2) ** 0.5\n",
        "    return dis\n",
        "\n",
        "\n",
        "def get_mean_height_of_bounding_boxes(bounding_boxes):\n",
        "    heights = []\n",
        "    for bounding_box in bounding_boxes:\n",
        "        x, y, w, h = bounding_box\n",
        "        heights.append(h)\n",
        "    return np.mean(heights)\n",
        "\n",
        "\n",
        "def get_result_from_tersseract(image_path):\n",
        "    output = subprocess.getoutput(\"tesseract \" + image_path + ocr_settings)\n",
        "    output = output.strip()\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vk1_PxzqzDGu"
      },
      "outputs": [],
      "source": [
        "def preprocessor(file_path):\n",
        "    image = Image.open(file_path).convert(\"RGB\")\n",
        "\n",
        "    processor = DetrImageProcessor.from_pretrained(PRETRAINED_MODEL)\n",
        "    model = DetrForObjectDetection.from_pretrained(PRETRAINED_MODEL)\n",
        "\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    target_sizes = torch.tensor([image.size[::-1]])\n",
        "    results = processor.post_process_object_detection(\n",
        "        outputs, target_sizes=target_sizes, threshold=0.9\n",
        "    )[0]\n",
        "\n",
        "    for score, label, box in zip(\n",
        "        results[\"scores\"], results[\"labels\"], results[\"boxes\"]\n",
        "    ):\n",
        "        box = [round(i, 2) for i in box.tolist()]\n",
        "        print(\n",
        "            f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
        "            f\"{round(score.item(), 3)} at location {box}\"\n",
        "        )\n",
        "    orig_size = list(image.size)\n",
        "\n",
        "    box[3] = orig_size[1]\n",
        "    box[1] = box[1] - 75\n",
        "    box[0] = 0\n",
        "    box[2] = orig_size[0]\n",
        "    image = image.crop(box)\n",
        "    np_image = np.asarray(image)\n",
        "    # переводим в черно-белое\n",
        "    grayscale_image = cv2.cvtColor(np_image, cv2.COLOR_BGR2GRAY)\n",
        "    thresholded_image = cv2.threshold(\n",
        "        grayscale_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU\n",
        "    )[1]\n",
        "    # меняем черное и белое\n",
        "    inverted_image = cv2.bitwise_not(thresholded_image)\n",
        "    # делаем текст и рамки толще\n",
        "    dilated_image = cv2.dilate(inverted_image, None, iterations=5)\n",
        "    return dilated_image, np_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIUZo3CmzLEe"
      },
      "outputs": [],
      "source": [
        "def table_extractor(dilated_image, np_image):\n",
        "    contours, hierarchy = cv2.findContours(\n",
        "        dilated_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE\n",
        "    )\n",
        "    image_with_all_contours = np_image.copy()\n",
        "    cv2.drawContours(image_with_all_contours, contours, -1, (0, 255, 0), 3)\n",
        "    rectangular_contours = []\n",
        "    for contour in contours:\n",
        "        peri = cv2.arcLength(contour, True)\n",
        "        approx = cv2.approxPolyDP(contour, 0.02 * peri, True)\n",
        "        if len(approx) == 4:\n",
        "            rectangular_contours.append(approx)\n",
        "\n",
        "    image_with_only_rectangular_contours = np_image.copy()\n",
        "    cv2.drawContours(\n",
        "        image_with_only_rectangular_contours, rectangular_contours, -1, (0, 255, 0), 3\n",
        "    )\n",
        "    max_area = 0\n",
        "    contour_with_max_area = None\n",
        "    for contour in rectangular_contours:\n",
        "        area = cv2.contourArea(contour)\n",
        "        if area > max_area:\n",
        "            max_area = area\n",
        "            contour_with_max_area = contour\n",
        "\n",
        "    image_with_contour_with_max_area = np_image.copy()\n",
        "    cv2.drawContours(\n",
        "        image_with_contour_with_max_area, [contour_with_max_area], -1, (0, 255, 0), 3\n",
        "    )\n",
        "    contour_with_max_area_ordered = order_points(contour_with_max_area)\n",
        "    image_with_points_plotted = np_image.copy()\n",
        "    for point in contour_with_max_area_ordered:\n",
        "        point_coordinates = (int(point[0]), int(point[1]))\n",
        "        image_with_points_plotted = cv2.circle(\n",
        "            image_with_points_plotted, point_coordinates, 10, (0, 0, 255), -1\n",
        "        )\n",
        "    existing_image_width = np_image.shape[1]\n",
        "    existing_image_width_reduced_by_10_percent = int(existing_image_width * 0.9)\n",
        "\n",
        "    distance_between_top_left_and_top_right = calculateDistanceBetween2Points(\n",
        "        contour_with_max_area_ordered[0], contour_with_max_area_ordered[1]\n",
        "    )\n",
        "    distance_between_top_left_and_bottom_left = calculateDistanceBetween2Points(\n",
        "        contour_with_max_area_ordered[0], contour_with_max_area_ordered[3]\n",
        "    )\n",
        "    aspect_ratio = (\n",
        "        distance_between_top_left_and_bottom_left\n",
        "        / distance_between_top_left_and_top_right\n",
        "    )\n",
        "    new_image_width = existing_image_width_reduced_by_10_percent\n",
        "    new_image_height = int(new_image_width * aspect_ratio)\n",
        "\n",
        "    pts1 = np.float32(contour_with_max_area_ordered)\n",
        "    pts2 = np.float32(\n",
        "        [\n",
        "            [0, 0],\n",
        "            [new_image_width, 0],\n",
        "            [new_image_width, new_image_height],\n",
        "            [0, new_image_height],\n",
        "        ]\n",
        "    )\n",
        "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
        "    perspective_corrected_image = cv2.warpPerspective(\n",
        "        dilated_image, matrix, (new_image_width, new_image_height)\n",
        "    )\n",
        "    perspective_corrected_orig_image = cv2.warpPerspective(\n",
        "        np_image, matrix, (new_image_width, new_image_height)\n",
        "    )\n",
        "    return perspective_corrected_image, perspective_corrected_orig_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvJ4TF1ezMKZ"
      },
      "outputs": [],
      "source": [
        "def text_recognizer(perspective_corrected_image, perspective_corrected_orig_image):\n",
        "    hor = np.array([[1, 1, 1, 1, 1, 1]])\n",
        "    vertical_lines_eroded_image = cv2.erode(\n",
        "        perspective_corrected_image, hor, iterations=100\n",
        "    )\n",
        "    vertical_lines_eroded_image = cv2.dilate(\n",
        "        vertical_lines_eroded_image, hor, iterations=100\n",
        "    )\n",
        "    ver = np.array([[1], [1], [1], [1], [1], [1], [1]])\n",
        "    horizontal_lines_eroded_image = cv2.erode(\n",
        "        perspective_corrected_image, ver, iterations=100\n",
        "    )\n",
        "    horizontal_lines_eroded_image = cv2.dilate(\n",
        "        horizontal_lines_eroded_image, ver, iterations=100\n",
        "    )\n",
        "    combined_image = cv2.add(vertical_lines_eroded_image, horizontal_lines_eroded_image)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
        "    combined_image_dilated = cv2.dilate(combined_image, kernel, iterations=7)\n",
        "    image_without_lines = cv2.subtract(\n",
        "        perspective_corrected_image, combined_image_dilated\n",
        "    )\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
        "    image_without_lines_noise_removed = cv2.erode(\n",
        "        image_without_lines, kernel, iterations=5\n",
        "    )\n",
        "    image_without_lines_noise_removed = cv2.dilate(\n",
        "        image_without_lines_noise_removed, kernel, iterations=5\n",
        "    )\n",
        "    kernel_to_remove_gaps_between_words = np.array(\n",
        "        [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
        "    )\n",
        "    dilated_image = cv2.dilate(\n",
        "        image_without_lines_noise_removed,\n",
        "        kernel_to_remove_gaps_between_words,\n",
        "        iterations=5,\n",
        "    )\n",
        "    simple_kernel = np.ones((5, 5), np.uint8)\n",
        "    dilated_image = cv2.dilate(\n",
        "        image_without_lines_noise_removed, simple_kernel, iterations=5\n",
        "    )\n",
        "    result = cv2.findContours(dilated_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = result[0]\n",
        "    image_with_contours_drawn = perspective_corrected_orig_image.copy()\n",
        "    cv2.drawContours(image_with_contours_drawn, contours, -1, (0, 255, 0), 3)\n",
        "    approximated_contours = []\n",
        "    for contour in contours:\n",
        "        approx = cv2.approxPolyDP(contour, 3, True)\n",
        "        approximated_contours.append(approx)\n",
        "    image_with_contours = perspective_corrected_orig_image.copy()\n",
        "    cv2.drawContours(image_with_contours, approximated_contours, -1, (0, 255, 0), 5)\n",
        "    bounding_boxes = []\n",
        "    image_with_all_bounding_boxes = perspective_corrected_orig_image.copy()\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        bounding_boxes.append((x, y, w, h))\n",
        "        image_with_all_bounding_boxes = cv2.rectangle(\n",
        "            image_with_all_bounding_boxes, (x, y), (x + w, y + h), (0, 255, 0), 3\n",
        "        )\n",
        "    bounding_boxes = sorted(bounding_boxes, key=lambda x: x[1])\n",
        "    mean_height = get_mean_height_of_bounding_boxes(bounding_boxes)\n",
        "    rows = []\n",
        "    half_of_mean_height = mean_height / 2\n",
        "    current_row = [bounding_boxes[0]]\n",
        "    for bounding_box in bounding_boxes[1:]:\n",
        "        current_bounding_box_y = bounding_box[1]\n",
        "        previous_bounding_box_y = current_row[-1][1]\n",
        "        distance_between_bounding_boxes = abs(\n",
        "            current_bounding_box_y - previous_bounding_box_y\n",
        "        )\n",
        "        if distance_between_bounding_boxes <= half_of_mean_height:\n",
        "            current_row.append(bounding_box)\n",
        "        else:\n",
        "            rows.append(current_row)\n",
        "            current_row = [bounding_box]\n",
        "    rows.append(current_row)\n",
        "    for row in rows:\n",
        "        row.sort(key=lambda x: x[0])\n",
        "    table = []\n",
        "    current_row = []\n",
        "    image_number = 0\n",
        "    for row in rows:\n",
        "        for bounding_box in row:\n",
        "            x, y, w, h = bounding_box\n",
        "            cropped_image = perspective_corrected_orig_image[y : y + h, x : x + w]\n",
        "            image_slice_path = SLICES_FOLDER + \"img_\" + str(image_number) + \".jpg\"\n",
        "            cv2.imwrite(image_slice_path, cropped_image)\n",
        "            results_from_ocr = get_result_from_tersseract(image_slice_path)\n",
        "            current_row.append(results_from_ocr)\n",
        "            image_number += 1\n",
        "        table.append(current_row)\n",
        "        current_row = []\n",
        "    return table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygX4pH86z0Dw"
      },
      "source": [
        "# Обработка выходных данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VwVG68sz4fi"
      },
      "outputs": [],
      "source": [
        "def delete_redundant_elements(table, iter=5):\n",
        "    filtered_table = table.copy()\n",
        "\n",
        "    for _ in range(iter):\n",
        "        for row in filtered_table:\n",
        "            for item in row:\n",
        "                if (len(item) < 6) or (len(item) > 12):\n",
        "                    row.remove(item)\n",
        "\n",
        "    return filtered_table\n",
        "\n",
        "\n",
        "def get_max_row_lenght(table):\n",
        "    max = 0\n",
        "\n",
        "    for row in table:\n",
        "        if len(row) > max:\n",
        "            max = len(row)\n",
        "\n",
        "    return max\n",
        "\n",
        "\n",
        "def delete_redundant_rows(table, iter=3):\n",
        "    filtered_table = table.copy()\n",
        "    max = get_max_row_lenght(table)\n",
        "\n",
        "    for _ in range(iter):\n",
        "        for row in filtered_table:\n",
        "            if (len(row) <= max / 3) or (len(row) <= 2):\n",
        "                filtered_table.remove(row)\n",
        "\n",
        "    return filtered_table\n",
        "\n",
        "\n",
        "def split_don_type(table):\n",
        "    filtered_table = []\n",
        "\n",
        "    for row in table:\n",
        "        filtered_table.append(\n",
        "            [splitted_item for item in row for splitted_item in item.split()]\n",
        "        )\n",
        "\n",
        "    return filtered_table\n",
        "\n",
        "\n",
        "def split_long_row(table):\n",
        "    updated_table = []\n",
        "\n",
        "    for row in table:\n",
        "        if len(row) > 10:\n",
        "            half_length = len(row) // 2\n",
        "            updated_table.append(row[:half_length])\n",
        "            updated_table.append(row[half_length:])\n",
        "        else:\n",
        "            updated_table.append(row)\n",
        "\n",
        "    return updated_table\n",
        "\n",
        "\n",
        "def change_values(value: str, values: dict) -> str:\n",
        "    if value in values.keys():\n",
        "        return values[value]\n",
        "    else:\n",
        "        return value\n",
        "\n",
        "\n",
        "def raw_table_filter(raw_pred):\n",
        "    filtered_table = delete_redundant_elements(raw_pred)\n",
        "    filtered_table = delete_redundant_rows(filtered_table)\n",
        "    filtered_table = split_don_type(filtered_table)\n",
        "\n",
        "    return filtered_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_i9dTsLN09gF"
      },
      "outputs": [],
      "source": [
        "# словарь с расшифровками\n",
        "\n",
        "don_type = {\n",
        "    \"кр/д\": \"Цельная кровь\",\n",
        "    \"крид\": \"Цельная кровь\",\n",
        "    \"кри\": \"Цельная кровь\",\n",
        "    \"т/ф\": \"Тромбоциты\",\n",
        "    \"п/ф\": \"Плазма\",\n",
        "    \"пл/д\": \"Плазма\",\n",
        "}\n",
        "\n",
        "pay_type = {\"(бв)\": \"Безвозмездно\", \"(6в)\": \"Безвозмездно\", \"(пл)\": \"Платно\"}\n",
        "\n",
        "\n",
        "def get_predictions_df(filtered_table, don_type, pay_type):\n",
        "    max_len = get_max_row_lenght(filtered_table)\n",
        "    row_len = 3\n",
        "    new_table = []\n",
        "    for i in range(len(filtered_table) * int(max_len / 3)):\n",
        "        new_row = [0 for _ in range(row_len)]\n",
        "        new_table.append(new_row)\n",
        "    counter = 0\n",
        "    row_counter = 0\n",
        "    if max_len == 8:\n",
        "        max_len += 1\n",
        "\n",
        "    for i in range(len(filtered_table)):\n",
        "        if max_len == 6:\n",
        "            pass\n",
        "        elif (\n",
        "            max_len == 9\n",
        "            and new_table[row_counter][2] == 0\n",
        "            and new_table[row_counter].count(0) < 3\n",
        "        ):\n",
        "            row_counter += 0\n",
        "        elif max_len == 9 and new_table[row_counter].count(0) == 3:\n",
        "            if row_counter % 3 == 1:\n",
        "                row_counter += 2\n",
        "            elif row_counter % 3 == 2:\n",
        "                row_counter += 1\n",
        "        for j in range(len(filtered_table[i])):\n",
        "            counter = 0\n",
        "            try:\n",
        "                datetime_object = pd.to_datetime(\n",
        "                    filtered_table[i][j].strip(\".\"), format=\"%d.%m.%Y\"\n",
        "                )\n",
        "                try:\n",
        "                    if new_table[row_counter - 1][2] == 0 and row_counter != 0:\n",
        "                        row_counter += 1\n",
        "                except:\n",
        "                    pass\n",
        "                if new_table[row_counter][counter] != 0:\n",
        "                    row_counter += 1\n",
        "                new_table[row_counter][counter] = filtered_table[i][j].strip(\".\")\n",
        "                continue\n",
        "\n",
        "            except:\n",
        "                counter += 1\n",
        "\n",
        "            if filtered_table[i][j] in don_type.keys():\n",
        "                if new_table[row_counter][counter] != 0:\n",
        "                    row_counter += 1\n",
        "                new_table[row_counter][counter] = change_values(\n",
        "                    filtered_table[i][j], don_type\n",
        "                )\n",
        "                continue\n",
        "            else:\n",
        "                counter += 1\n",
        "\n",
        "            if filtered_table[i][j] in pay_type.keys():\n",
        "                new_table[row_counter][counter] = change_values(\n",
        "                    filtered_table[i][j], pay_type\n",
        "                )\n",
        "                row_counter += 1\n",
        "                continue\n",
        "            else:\n",
        "                counter += 1\n",
        "\n",
        "    new_table = pd.DataFrame(\n",
        "        new_table, columns=[\"Дата донации\", \"Класс крови\", \"Тип донации\"]\n",
        "    )\n",
        "\n",
        "    return new_table\n",
        "\n",
        "\n",
        "def reshape(table, preds):\n",
        "    if get_max_row_lenght(preds) == 6:\n",
        "        temp_table_1 = table.iloc[::2, :]\n",
        "        temp_table_2 = table.iloc[1::2, :]\n",
        "\n",
        "        reshaped_table = pd.concat([temp_table_1, temp_table_2]).reset_index(drop=True)\n",
        "\n",
        "        return reshaped_table\n",
        "\n",
        "    else:\n",
        "        temp_table_1 = table.iloc[::3, :]\n",
        "        temp_table_2 = table.iloc[1::3, :]\n",
        "        temp_table_3 = table.iloc[2::3, :]\n",
        "\n",
        "        reshaped_table = pd.concat(\n",
        "            [temp_table_1, temp_table_2, temp_table_3]\n",
        "        ).reset_index(drop=True)\n",
        "\n",
        "        return reshaped_table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AxTzlW7z9F7"
      },
      "source": [
        "# Расчет accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxqqEQDE0BPS"
      },
      "outputs": [],
      "source": [
        "def accuracy_score(table_pred, table_true):\n",
        "    if table_pred.shape == table_true.shape:\n",
        "        rows = int(table_pred.shape[0])\n",
        "        cols = int(table_pred.shape[1])\n",
        "        total = rows * cols\n",
        "        correct = 0\n",
        "\n",
        "        for row in range(rows):\n",
        "            for col in range(cols):\n",
        "                if table_pred.iloc[row, col] == table_true.iloc[row, col]:\n",
        "                    correct += 1\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "        return correct / total\n",
        "\n",
        "    else:\n",
        "        print(\"Shapes of table_pred and table_true does not match!\")\n",
        "\n",
        "\n",
        "def accuracy_check(table_pred, csv_orig_path):\n",
        "    accuracy_columns = [\"Дата донации\", \"Класс крови\", \"Тип донации\"]\n",
        "    table_orig = pd.read_csv(csv_orig_path)\n",
        "\n",
        "    table_pred = table_pred[accuracy_columns]\n",
        "    table_orig = table_orig[accuracy_columns]\n",
        "\n",
        "    return accuracy_score(table_pred, table_orig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7Xi1acJ1gLZ"
      },
      "source": [
        "# Расчет ACCURACY SCORE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIR7VDlXzfOm"
      },
      "outputs": [],
      "source": [
        "images = [img for img in os.listdir(DIRECTORY) if img.endswith(\".jpg\")]\n",
        "csvs = [csv for csv in os.listdir(DIRECTORY) if csv.endswith(\".csv\")]\n",
        "\n",
        "images_test = [\"213950.jpg\", \"225629 .jpg\", \"233749 .jpg\", \"238716.jpg\"]\n",
        "\n",
        "images_test_2 = [\n",
        "    \"213950.jpg\",\n",
        "    \"225629 .jpg\",\n",
        "    \"227414.jpg\",\n",
        "    \"231820 .jpg\",\n",
        "    \"233749 .jpg\",\n",
        "    \"238716.jpg\",\n",
        "    #'243478 .jpg',\n",
        "    \"254586 .jpg\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "id": "OS3RMhxX14W2",
        "outputId": "c3f30126-b7db-4707-ca79-81ab72c07fb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IMAGE: 213950.jpg\n",
            "Detected table with confidence 0.985 at location [248.68, 2877.95, 3178.29, 4203.68]\n",
            "ACCURACY = 1.0\n",
            "------------------------------------------------------------------------------------\n",
            "IMAGE: 225629 .jpg\n",
            "Detected table with confidence 0.992 at location [238.97, 2099.19, 2749.85, 2843.4]\n",
            "ACCURACY = 0.7407407407407407\n",
            "------------------------------------------------------------------------------------\n",
            "IMAGE: 227414.jpg\n",
            "Detected table with confidence 0.988 at location [163.26, 1326.01, 1267.37, 1679.61]\n",
            "Shapes of table_pred and table_true does not match!\n",
            "ACCURACY = None\n",
            "------------------------------------------------------------------------------------\n",
            "IMAGE: 231820 .jpg\n",
            "Detected table with confidence 0.994 at location [90.11, 1041.39, 1102.32, 1279.97]\n",
            "Shapes of table_pred and table_true does not match!\n",
            "ACCURACY = None\n",
            "------------------------------------------------------------------------------------\n",
            "IMAGE: 233749 .jpg\n",
            "Detected table with confidence 0.989 at location [282.43, 2733.59, 2877.99, 3466.03]\n",
            "ACCURACY = 0.7936507936507936\n",
            "------------------------------------------------------------------------------------\n",
            "IMAGE: 238716.jpg\n",
            "Detected table with confidence 0.992 at location [430.39, 2345.7, 2589.67, 3391.42]\n",
            "Shapes of table_pred and table_true does not match!\n",
            "ACCURACY = None\n",
            "------------------------------------------------------------------------------------\n",
            "IMAGE: 243478 .jpg\n",
            "Detected table with confidence 0.903 at location [31.38, 559.58, 418.25, 769.37]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-d25b9d328b33>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# вытаскиваем текст из таблицы\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtable_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_recognizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_image_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# фильтруем текст\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-c748d703b0ef>\u001b[0m in \u001b[0;36mtext_recognizer\u001b[0;34m(perspective_corrected_image, perspective_corrected_orig_image)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mhalf_of_mean_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_height\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mcurrent_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mbounding_boxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbounding_box\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbounding_boxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mcurrent_bounding_box_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbounding_box\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "# для каждой картинки из images\n",
        "for img in images_test_2:\n",
        "    # выводим имя картинки\n",
        "    print(f\"IMAGE: {img}\")\n",
        "\n",
        "    # обрабатываем картинку\n",
        "    preprocessed_image, np_image = preprocessor(DIRECTORY + img)\n",
        "\n",
        "    # экстрактим таблицу\n",
        "    table_image, table_image_orig = table_extractor(preprocessed_image, np_image)\n",
        "\n",
        "    # вытаскиваем текст из таблицы\n",
        "    table_text = text_recognizer(table_image, table_image_orig)\n",
        "\n",
        "    # фильтруем текст\n",
        "    filtered_text = raw_table_filter(table_text)\n",
        "\n",
        "    # приводим предсказания к DataFrame\n",
        "    df_pred = get_predictions_df(filtered_text, don_type, pay_type)\n",
        "\n",
        "    # меняем порядок выдачи записей\n",
        "    df_pred = reshape(df_pred, filtered_text)\n",
        "\n",
        "    # сохраняем предсказания в csv формат\n",
        "    df_pred.to_csv(f\"./csv/\" + img[:-4].strip() + \".csv\")\n",
        "\n",
        "    # считаем accuracy\n",
        "    acc = accuracy_check(df_pred, DIRECTORY + img[:-4].strip() + \".csv\")\n",
        "    print(f\"ACCURACY = {acc}\")\n",
        "    print(\"-\" * 84)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NovMGV1GryS"
      },
      "source": [
        "# DEBUG CODE BELOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkaPVBNAFAWJ",
        "outputId": "bdae6d35-7c0a-44cf-b15d-1119d7868707"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IMAGE: 238716.jpg\n",
            "Detected table with confidence 0.992 at location [430.39, 2345.7, 2589.67, 3391.42]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[['', '1', 'к', 'Колво', 'Дата', 'а', 'Колво', 'Дата', 'а', 'Колво'],\n",
              " ['1', '2', '3', '4', '5', '6', 'Й', '8', '9'],\n",
              " ['кр/д (бв)',\n",
              "  '400',\n",
              "  '10.08.2017',\n",
              "  'кр/д (бв)',\n",
              "  '450',\n",
              "  '20.10.2020',\n",
              "  'кр/д (бв)',\n",
              "  '450'],\n",
              " ['крид (бв)',\n",
              "  '413',\n",
              "  '16.12.2017',\n",
              "  'кр/д (бв)',\n",
              "  '400',\n",
              "  '23.12.2020',\n",
              "  'кр/д (бв)',\n",
              "  '450'],\n",
              " ['кр/д (бв)',\n",
              "  '413',\n",
              "  '26.04.2018',\n",
              "  'кр/д (бв)',\n",
              "  '450',\n",
              "  '17.02.2021',\n",
              "  'пл/д (бв)',\n",
              "  '600'],\n",
              " ['кр/д (бв)',\n",
              "  '400',\n",
              "  '12.07.2018',\n",
              "  'кр/д (бв)',\n",
              "  '400',\n",
              "  '03.03.2021',\n",
              "  'кр/д (бв)',\n",
              "  '450'],\n",
              " ['кр/д (бв)',\n",
              "  '400',\n",
              "  '15.11.2018',\n",
              "  'кр/д (бв)',\n",
              "  '450',\n",
              "  '04.05.2021',\n",
              "  'кр/д (бв)',\n",
              "  '450'],\n",
              " ['кр/д (бв)',\n",
              "  '400',\n",
              "  '27.03.2019',\n",
              "  'кр/д (бв)',\n",
              "  '370',\n",
              "  '04.08.2021',\n",
              "  'кр/д (бв)',\n",
              "  '450'],\n",
              " ['кр/д (бв)',\n",
              "  'кр/д (бв)',\n",
              "  '400',\n",
              "  '400',\n",
              "  '06.06.2019',\n",
              "  '17.08.2019',\n",
              "  'кр/д (бв)',\n",
              "  'кр/д (бв)',\n",
              "  '450',\n",
              "  '450',\n",
              "  '29.10.2021',\n",
              "  '29.12.2021',\n",
              "  'кр/д (бв)',\n",
              "  'кр/д (бв)',\n",
              "  '450',\n",
              "  '450',\n",
              "  '1',\n",
              "  '1',\n",
              "  '1'],\n",
              " ['кр/д (бв)',\n",
              "  '450',\n",
              "  '12.11.2019',\n",
              "  'кр/д (бв)',\n",
              "  '450',\n",
              "  '22.03.2022',\n",
              "  'кр/д (бв)',\n",
              "  '450'],\n",
              " ['кр/д (бв)',\n",
              "  '400',\n",
              "  '29.01.2020',\n",
              "  'кр/д (бв)',\n",
              "  '450',\n",
              "  '26.05.2022',\n",
              "  'кр/д (бв)',\n",
              "  '450'],\n",
              " ['кр/д (бв)',\n",
              "  '400',\n",
              "  '01.04.2020',\n",
              "  'кр/д (бв)',\n",
              "  '450',\n",
              "  '10.08.2022',\n",
              "  'кр/д (бв)',\n",
              "  '450'],\n",
              " ['кр/д (бв)',\n",
              "  '',\n",
              "  '450',\n",
              "  '03.08.2020',\n",
              "  'кр/д (бв)',\n",
              "  '450',\n",
              "  '14.12.2022',\n",
              "  'кр/д (бв)',\n",
              "  '450']]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# выводим имя картинки\n",
        "print(\"IMAGE: 238716.jpg\")\n",
        "\n",
        "# обрабатываем картинку\n",
        "preprocessed_image, np_image = preprocessor(DIRECTORY + \"238716.jpg\")\n",
        "\n",
        "# экстрактим таблицу\n",
        "table_image, table_image_orig = table_extractor(preprocessed_image, np_image)\n",
        "\n",
        "# вытаскиваем текст из таблицы\n",
        "table_text = text_recognizer(table_image, table_image_orig)\n",
        "table_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQyevV2dFVeK",
        "outputId": "bad6e1ec-bf55-4aa7-e086-5215455beb91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['кр/д', '(бв)', '10.08.2017', 'кр/д', '(бв)', '20.10.2020', 'кр/д', '(бв)'],\n",
              " ['крид', '(бв)', '16.12.2017', 'кр/д', '(бв)', '23.12.2020', 'кр/д', '(бв)'],\n",
              " ['кр/д', '(бв)', '26.04.2018', 'кр/д', '(бв)', '17.02.2021', 'пл/д', '(бв)'],\n",
              " ['кр/д', '(бв)', '12.07.2018', 'кр/д', '(бв)', '03.03.2021', 'кр/д', '(бв)'],\n",
              " ['кр/д', '(бв)', '15.11.2018', 'кр/д', '(бв)', '04.05.2021', 'кр/д', '(бв)'],\n",
              " ['кр/д', '(бв)', '27.03.2019', 'кр/д', '(бв)', '04.08.2021', 'кр/д', '(бв)'],\n",
              " ['кр/д', '(бв)', 'кр/д', '(бв)', '06.06.2019', '17.08.2019', 'кр/д', '(бв)'],\n",
              " ['кр/д', '(бв)', '29.10.2021', '29.12.2021', 'кр/д', '(бв)', 'кр/д', '(бв)'],\n",
              " ['кр/д', '(бв)', '12.11.2019', 'кр/д', '(бв)', '22.03.2022', 'кр/д', '(бв)'],\n",
              " ['кр/д', '(бв)', '29.01.2020', 'кр/д', '(бв)', '26.05.2022', 'кр/д', '(бв)'],\n",
              " ['кр/д', '(бв)', '01.04.2020', 'кр/д', '(бв)', '10.08.2022', 'кр/д', '(бв)'],\n",
              " ['кр/д', '(бв)', '03.08.2020', 'кр/д', '(бв)', '14.12.2022', 'кр/д', '(бв)']]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# фильтруем текст\n",
        "filtered_text = raw_table_filter(table_text)\n",
        "filtered_text = split_long_row(filtered_text)\n",
        "filtered_text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emIf9dBkGyuG"
      },
      "source": [
        "## формируется много лишних нулевых строк для этой картинки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "syYEbYp4FXFG",
        "outputId": "3b34a5d8-d8a4-4c58-cc1e-7b6f79e2c02e"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-85c1198dd819>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# приводим предсказания к DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdon_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpay_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-da442607b983>\u001b[0m in \u001b[0;36mget_predictions_df\u001b[0;34m(filtered_table, don_type, pay_type)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfiltered_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdon_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_counter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                     \u001b[0mrow_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mnew_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_counter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchange_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdon_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "# приводим предсказания к DataFrame\n",
        "df_pred = get_predictions_df(filtered_text, don_type, pay_type)\n",
        "df_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MI-ivAZFqZo"
      },
      "outputs": [],
      "source": [
        "# меняем порядок выдачи записей\n",
        "df_pred = reshape(df_pred, filtered_text)\n",
        "\n",
        "# сохраняем предсказания в csv формат\n",
        "df_pred.to_csv(f\"./csv/\" + \"238716.csv\")\n",
        "\n",
        "# считаем accuracy\n",
        "acc = accuracy_check(df_pred, DIRECTORY + \"238716.csv\")\n",
        "print(f\"ACCURACY = {acc}\")\n",
        "print(\"-\" * 84)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
